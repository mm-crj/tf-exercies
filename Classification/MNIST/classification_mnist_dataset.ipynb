{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "First we need to get the dataset. Scikit-Learn provides many helper functions to download popular datasets. MNIST is one of them. The following code fetches the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape\n",
    "#y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images, and each image has 784 features. This is because each image\n",
    "is 28×28 pixels, and each feature simply represents one pixel’s intensity, from 0\n",
    "(white) to 255 (black). Let us plot one of the images to see how it is like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "some_digit = X[69982]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "y[69982]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is the picture of a digit 9, and the label also tells us so. Next we need to split the data set in to training and test set, actully this is already done. The **MNIST** dataset is actually already split into a training set (the first 60,000 images) and a test set (the last 10,000 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After spliting the data we have also suffled the data so that the digits are evenly distributed and we have no problem while performing cross validation.\n",
    "\n",
    "## Training a Binary Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')\n",
    "#y_train_5= y_train_5.astype(int) \n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96195, 0.9541 , 0.97055])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zenith/environments/anaconda3/envs/tf-testbed/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96195\n",
      "0.9541\n",
      "0.97055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = (y_train_5[train_index])\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = (y_train_5[test_index])\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96195, 0.9541 , 0.97055])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of classifier seems to be around $95\\%$. But here is the catch, only about $10\\%$ of the images are actually 5s. So even if the classifier just guessed `False` all the time it would have an accuracy of $90\\%$. This is why accuracy is not a measure of the performance of a Classifier, specially on skewed datasets where one of the labels is much more frequent than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A much better way to evaluate the performance of a classifier is to look at the confu‐\n",
    "sion matrix. The general idea is to count the number of times instances of class A are\n",
    "classified as class B. For example, to know the number of times the classifier confused\n",
    "images of 5s with 3s, you would look in the 5th row and 3rd column of the confusion\n",
    "matrix. To compute a confusion matrix we need have a prediction for each of the values we want to test. So we use the function `cross_val_predict`, which performs cross-validation across k folds of the training set and outputs the predictions for each fold. So we have a predction for each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53584,   995],\n",
       "       [ 1273,  4148]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kfold cross-validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in a confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (the negative class): 53,272 of them were correctly classified as non-5s (they are called true negatives), while the remaining 1,307 were wrongly classified as 5s (false positives). The second row considers the images of 5s (the positive class): 1,077 were wrongly classified as non-5s (false negatives), while the remaining 4,344 were correctly classified as 5s (true positives). A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal.\n",
    "\n",
    "###### Precision and recall\n",
    "*Precision*= $\\frac{TP}{TP+FP}$\n",
    "\n",
    "*Recall*= $\\frac{TP}{TP+FN}$\n",
    "\n",
    "Now we cant use precission alone because one easy way to game the precision metric is to make one prediction and make sure its correct. Thats $100\\%$ precise, but not a very good prediction. So another metric that goes along with it is *recall* that is the fraction of the total amount of relevant instances that were actually retrieved. And precision measure the fraction of relevant cases retrieved out of the total retrieved cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score is 0.8065331518568929 and       recall score is0.7651724774026932.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "print(f\"precision_score is {precision_score(y_train_5, y_train_pred)} and \\\n",
    "      recall score is{recall_score(y_train_5, y_train_pred)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the confusion matrix precision_score sould be 0.8065331518568929 and  \n",
      " recall score should be 0.7651724774026932.\n"
     ]
    }
   ],
   "source": [
    "print(f\"According to the confusion matrix precision_score sould be {4148/(995+4148)} and  \\n recall score should be {4148/(1273+4148)}.\")\n",
    " #presision\n",
    "# recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the 5 detector is correct about $81\\%$ of the time and it detects about $77\\%$ of all the 5s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision/Recall Tradeoff\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
